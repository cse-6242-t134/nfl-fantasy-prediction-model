{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nfl_data_py as nfl\n",
    "import datetime as dt\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Suppress FutureWarnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background/Ideas\n",
    "\n",
    "- Features will be based off seasonal,weekly,career, and last 5 based values\n",
    "- Idea is that certain players which can be differentiated by career based values paired with weekly performance and or seasonal (team strength proxy) can be paired to build something relatively predictive.\n",
    "- Interactivity can be dependent on clicking and choosing assortment of players and identifying/projecting current projections.\n",
    "- Data seems to get updated weekly so these predictions would change over time as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "This section focuses on pulling the data and prepping/aggregating the dependent variable. (Fantasy Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024 done.\n",
      "2023 done.\n",
      "2022 done.\n",
      "2021 done.\n",
      "2020 done.\n",
      "2019 done.\n",
      "2018 done.\n",
      "2017 done.\n",
      "2016 done.\n",
      "2015 done.\n",
      "2014 done.\n",
      "2013 done.\n",
      "2012 done.\n",
      "2011 done.\n",
      "2010 done.\n",
      "2009 done.\n",
      "2008 done.\n",
      "2007 done.\n",
      "2006 done.\n",
      "2005 done.\n",
      "2004 done.\n",
      "2003 done.\n",
      "2002 done.\n",
      "2001 done.\n",
      "2000 done.\n",
      "1999 done.\n",
      "Downcasting floats.\n",
      "Downcasting floats.\n"
     ]
    }
   ],
   "source": [
    "roster_data = nfl.import_seasonal_rosters([2024,2023,2022,2021,2020,2019,2018,2017,2016,2015,2014,2013,2012,2011,2010,2009,2008,2007,2006,2005,2004,2003,2002,2001,2000,1999])\n",
    "pbp_df = pd.DataFrame(nfl.import_pbp_data([2024,2023,2022,2021,2020,2019,2018,2017,2016,2015,2014,2013,2012,2011,2010,2009,2008,2007,2006,2005,2004,2003,2002,2001,2000,1999]))\n",
    "weekly_df = pd.DataFrame(nfl.import_weekly_data([2024,2023,2022,2021,2020,2019,2018,2017,2016,2015,2014,2013,2012,2011,2010,2009,2008,2007,2006,2005,2004,2003,2002,2001,2000,1999]))\n",
    "# injuries_df = pd.DataFrame(nfl.import_injuries([2024,2023,2022,2021,2020,2019,2018,2017,2016,2015,2014,2013,2012,2011,2010,2009,2008,2007,2006,2005,2004,2003,2002,2001,2000]))\n",
    "schedules_df = pd.DataFrame(nfl.import_schedules([2024,2023,2022,2021,2020,2019,2018,2017,2016,2015,2014,2013,2012,2011,2010,2009,2008,2007,2006,2005,2004,2003,2002,2001,2000,1999]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Data Transformations\n",
    "\n",
    "- Getting General RB and WR stats and creating complete dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_1040\\2951882464.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  receiver_rusher_stats['two_points'] = np.where(receiver_rusher_stats['two_point_conv_result'] == 'success',1,0)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_1040\\2951882464.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  receiver_rusher_stats['two_points'] = np.where(receiver_rusher_stats['two_point_conv_result'] == 'success',1,0)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_1040\\2951882464.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  receiver_rusher_stats.rename(columns = {'complete_pass':'reception'},inplace = True)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_1040\\2951882464.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  team['team'] = team['team'].replace({'OAK':'LV', 'STL':'LA', 'SD':'LAC','HST':'HOU', 'BLT':'BAL', 'CLV':'CLE','SL':'LA','ARZ':'ARI'})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Missing Opponent:1972\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>game_date</th>\n",
       "      <th>week</th>\n",
       "      <th>div_game</th>\n",
       "      <th>posteam</th>\n",
       "      <th>defteam</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>weather</th>\n",
       "      <th>stadium</th>\n",
       "      <th>spread_line</th>\n",
       "      <th>total_line</th>\n",
       "      <th>roof</th>\n",
       "      <th>surface</th>\n",
       "      <th>temp</th>\n",
       "      <th>wind</th>\n",
       "      <th>home_coach</th>\n",
       "      <th>away_coach</th>\n",
       "      <th>player_id</th>\n",
       "      <th>player_name</th>\n",
       "      <th>season</th>\n",
       "      <th>home_score</th>\n",
       "      <th>away_score</th>\n",
       "      <th>team</th>\n",
       "      <th>depth_chart_position</th>\n",
       "      <th>passing_yards</th>\n",
       "      <th>air_yards</th>\n",
       "      <th>pass_touchdown</th>\n",
       "      <th>pass_attempt</th>\n",
       "      <th>reception</th>\n",
       "      <th>interception</th>\n",
       "      <th>rush_attempt</th>\n",
       "      <th>rushing_yards</th>\n",
       "      <th>rush_touchdown</th>\n",
       "      <th>lateral_rush</th>\n",
       "      <th>receiving_yards</th>\n",
       "      <th>yards_after_catch</th>\n",
       "      <th>touchdown</th>\n",
       "      <th>fumble</th>\n",
       "      <th>two_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001_01_ATL_SF</td>\n",
       "      <td>2001-09-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ATL</td>\n",
       "      <td>SF</td>\n",
       "      <td>SF</td>\n",
       "      <td>ATL</td>\n",
       "      <td>partly cloudy Temp: 68째 F, Humidity: 63%, Wind...</td>\n",
       "      <td>3COM Park</td>\n",
       "      <td>3.5</td>\n",
       "      <td>46.0</td>\n",
       "      <td>outdoors</td>\n",
       "      <td>grass</td>\n",
       "      <td>68.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Steve Mariucci</td>\n",
       "      <td>Dan Reeves</td>\n",
       "      <td>00-0000316</td>\n",
       "      <td>J.Anderson</td>\n",
       "      <td>2001</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>RB</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001_01_ATL_SF</td>\n",
       "      <td>2001-09-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ATL</td>\n",
       "      <td>SF</td>\n",
       "      <td>SF</td>\n",
       "      <td>ATL</td>\n",
       "      <td>partly cloudy Temp: 68째 F, Humidity: 63%, Wind...</td>\n",
       "      <td>3COM Park</td>\n",
       "      <td>3.5</td>\n",
       "      <td>46.0</td>\n",
       "      <td>outdoors</td>\n",
       "      <td>grass</td>\n",
       "      <td>68.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Steve Mariucci</td>\n",
       "      <td>Dan Reeves</td>\n",
       "      <td>00-0002876</td>\n",
       "      <td>C.Chandler</td>\n",
       "      <td>2001</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>QB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          game_id   game_date  week  div_game posteam defteam home_team  \\\n",
       "0  2001_01_ATL_SF  2001-09-09     1         1     ATL      SF        SF   \n",
       "1  2001_01_ATL_SF  2001-09-09     1         1     ATL      SF        SF   \n",
       "\n",
       "  away_team                                            weather    stadium  \\\n",
       "0       ATL  partly cloudy Temp: 68째 F, Humidity: 63%, Wind...  3COM Park   \n",
       "1       ATL  partly cloudy Temp: 68째 F, Humidity: 63%, Wind...  3COM Park   \n",
       "\n",
       "   spread_line  total_line      roof surface  temp  wind      home_coach  \\\n",
       "0          3.5        46.0  outdoors   grass  68.0  12.0  Steve Mariucci   \n",
       "1          3.5        46.0  outdoors   grass  68.0  12.0  Steve Mariucci   \n",
       "\n",
       "   away_coach   player_id player_name  season  home_score  away_score team  \\\n",
       "0  Dan Reeves  00-0000316  J.Anderson    2001        16.0        13.0  ATL   \n",
       "1  Dan Reeves  00-0002876  C.Chandler    2001        16.0        13.0  ATL   \n",
       "\n",
       "  depth_chart_position  passing_yards  air_yards  pass_touchdown  \\\n",
       "0                   RB            8.0        0.0             0.0   \n",
       "1                   QB            0.0        0.0             0.0   \n",
       "\n",
       "   pass_attempt  reception  interception  rush_attempt  rushing_yards  \\\n",
       "0           2.0        1.0           0.0          26.0           86.0   \n",
       "1           0.0        0.0           0.0           3.0           16.0   \n",
       "\n",
       "   rush_touchdown  lateral_rush  receiving_yards  yards_after_catch  \\\n",
       "0             1.0           0.0              8.0                0.0   \n",
       "1             0.0           0.0              0.0                0.0   \n",
       "\n",
       "   touchdown  fumble  two_points  \n",
       "0        1.0     0.0           0  \n",
       "1        0.0     0.0           0  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Basic PBP Passing Stats\n",
    "\n",
    "def get_opposing_team(df):\n",
    "    if df['home_team'] == df['team']:\n",
    "        val = df['away_team']\n",
    "    elif df['away_team'] == df['team']:\n",
    "        val = df['home_team']\n",
    "    else:\n",
    "        val = None\n",
    "\n",
    "    return val\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# team = roster_data[roster_data['depth_chart_position'].isin(['RB','WR'])][['season','player_id','team','depth_chart_position']]\n",
    "\n",
    "team = roster_data[['season','player_id','team','depth_chart_position']]\n",
    "\n",
    "receiver_rusher_stats =  pbp_df[(pbp_df['receiver_player_id'].notnull()) | (pbp_df['rusher_player_id'].notnull())]\n",
    "                         \n",
    "\n",
    "receiver_rusher_stats['two_points'] = np.where(receiver_rusher_stats['two_point_conv_result'] == 'success',1,0)\n",
    "                         \n",
    "receiver_rusher_stats.rename(columns = {'complete_pass':'reception'},inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "receiver_stats= receiver_rusher_stats.groupby(['game_id', 'game_date', 'week','div_game','posteam','defteam', 'home_team', 'away_team', 'weather', 'stadium',  'spread_line', 'total_line', 'roof', 'surface', 'temp', 'wind', 'home_coach', 'away_coach', 'receiver_player_id', 'receiver_player_name','season']).agg({\n",
    "    'passing_yards': 'sum',\n",
    "    'air_yards': 'sum',\n",
    "    'pass_touchdown': 'sum', \n",
    "    'pass_attempt': 'sum',\n",
    "    'reception': 'sum',\n",
    "    'interception': 'sum', #the passing stats are duplicated for receivers\n",
    "    'rush_attempt': 'sum',\n",
    "    'rushing_yards': 'sum',# Sum passing yards\n",
    "    'rush_touchdown': 'sum',\n",
    "    'lateral_rush': 'sum',\n",
    "    'receiving_yards': 'sum',\n",
    "    'yards_after_catch':'sum',\n",
    "    'touchdown':'sum',\n",
    "    'fumble': 'sum',\n",
    "    'two_points': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "rushing_stats = receiver_rusher_stats.groupby(['game_id', 'game_date', 'week', 'div_game','posteam','defteam', 'home_team', 'away_team', 'weather', 'stadium',  'spread_line', 'total_line', 'roof', 'surface', 'temp', 'wind', 'home_coach', 'away_coach', 'rusher_player_id', 'rusher_player_name','season']).agg({\n",
    "    'passing_yards': 'sum',\n",
    "    'air_yards': 'sum',\n",
    "    'pass_touchdown': 'sum', \n",
    "    'pass_attempt': 'sum',\n",
    "    'reception': 'sum',\n",
    "    'interception': 'sum',\n",
    "    'rush_attempt': 'sum',\n",
    "    'rushing_yards': 'sum',# Sum passing yards\n",
    "    'rush_touchdown': 'sum',\n",
    "    'lateral_rush': 'sum',\n",
    "    'receiving_yards': 'sum',\n",
    "    'yards_after_catch': 'sum',\n",
    "    'touchdown':'sum',\n",
    "    'fumble': 'sum',\n",
    "    'two_points': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "## Grabbing seasonal info\n",
    "\n",
    "\n",
    "team['team'] = team['team'].replace({'OAK':'LV', 'STL':'LA', 'SD':'LAC','HST':'HOU', 'BLT':'BAL', 'CLV':'CLE','SL':'LA','ARZ':'ARI'})\n",
    "\n",
    "\n",
    "# team.rename(columns = {'player_id':'passer_player_id'},inplace = True)\n",
    "\n",
    "## Standardizing Columns\n",
    "rushing_stats.rename(columns = {'rusher_player_id':'player_id'}, inplace = True)\n",
    "\n",
    "receiver_stats.rename(columns = {'receiver_player_id':'player_id'}, inplace = True)\n",
    "\n",
    "rushing_stats.rename(columns = {'rusher_player_name':'player_name'}, inplace = True)\n",
    "\n",
    "receiver_stats.rename(columns = {'receiver_player_name':'player_name'}, inplace = True)\n",
    "\n",
    "\n",
    "rusher_receiver_df = pd.concat([receiver_stats,rushing_stats])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rusher_receiver_df = rusher_receiver_df.merge(team, on = ['player_id','season'], how = 'inner')\n",
    "\n",
    "\n",
    "## Aggregate average score to opposition \n",
    "\n",
    "rusher_receiver_df['opponent_team'] = rusher_receiver_df.apply(get_opposing_team,axis = 1)\n",
    "\n",
    "print('Number Missing Opponent:' + str(rusher_receiver_df[rusher_receiver_df['opponent_team'].isna()].shape[0]))\n",
    "rusher_receiver_df = rusher_receiver_df[~rusher_receiver_df['opponent_team'].isna()]\n",
    "\n",
    "\n",
    "\n",
    "game_score_info = schedules_df[['season','home_score','away_score','game_id']].copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rusher_receiver_df = rusher_receiver_df.merge(game_score_info, on = ['game_id','season'], how = 'left')\n",
    "\n",
    "\n",
    "\n",
    "rusher_receiver_df = rusher_receiver_df.groupby(['game_id', 'game_date', 'week', 'div_game', 'posteam','defteam','home_team', 'away_team', 'weather', 'stadium',  'spread_line', 'total_line', 'roof', 'surface', 'temp', 'wind', 'home_coach', 'away_coach', 'player_id', 'player_name','season','home_score','away_score','team','depth_chart_position']).agg({\n",
    "    'passing_yards': 'sum',\n",
    "    'air_yards': 'sum',\n",
    "    'pass_touchdown': 'sum', \n",
    "    'pass_attempt': 'sum',\n",
    "    'reception': 'sum',\n",
    "    'interception': 'sum',\n",
    "    'rush_attempt': 'sum',\n",
    "    'rushing_yards': 'sum',# Sum passing yards\n",
    "    'rush_touchdown': 'sum',\n",
    "    'lateral_rush': 'sum',\n",
    "    'receiving_yards': 'sum',\n",
    "    'yards_after_catch': 'sum',\n",
    "    'touchdown':'sum',\n",
    "    'fumble': 'sum',\n",
    "    'two_points': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "#Checking the passing stats dataframe\n",
    "rusher_receiver_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Fantasy Points Column\n",
    "\n",
    "\n",
    "Offensive Players:\n",
    "\n",
    "- Passing Yards: 1 point per 25 yards\n",
    "- Passing Touchdowns: 4 points\n",
    "- Passing Interceptions: -2 points\n",
    "- Rushing Yards: 1 point per 10 yards\n",
    "- Rushing Touchdowns: 6 points\n",
    "- Receptions: 1 points (only if using PPR scoring)\n",
    "- Receiving Yards: 1 point per 10 yards\n",
    "- Receiving Touchdowns: 6 points\n",
    "- 2-Point Conversions: 2 points\n",
    "- Fumbles Lost: -2 points\n",
    "- Fumble Recovered for a Touchdown: 6 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "rusher_receiver_df['fantasy_points'] = ((rusher_receiver_df['passing_yards']/25 )\n",
    "                                         + (rusher_receiver_df['pass_touchdown'] * 4) + \n",
    "                                         (rusher_receiver_df['interception'] * -2) +\n",
    "                                         (rusher_receiver_df['reception'] * 1) +\n",
    "                                         (rusher_receiver_df['touchdown'] * 6) +\n",
    "                                         (rusher_receiver_df['receiving_yards'] * .1) +\n",
    "                                         (rusher_receiver_df['fumble'] * -2) +\n",
    "                                         (rusher_receiver_df['two_points'] * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     8.12\n",
       "1     1.14\n",
       "2    13.24\n",
       "3     6.64\n",
       "4     7.36\n",
       "Name: fantasy_points, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rusher_receiver_df.head(5)['fantasy_points']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_rusher_receiver_game_level = rusher_receiver_df.groupby(['game_id', 'game_date', 'week', 'season', 'posteam', 'defteam', 'player_name', 'player_id']).agg({\n",
    "    # Game level\n",
    "    'home_team': 'first',\n",
    "    'away_team': 'first',\n",
    "\n",
    "    # Play level\n",
    "    'fantasy_points': 'sum',\n",
    "    'passing_yards': 'sum',\n",
    "    'air_yards': 'sum',\n",
    "    'pass_touchdown': 'sum', \n",
    "    'pass_attempt': 'sum',\n",
    "    'reception': 'sum',\n",
    "    'interception': 'sum',\n",
    "    'rush_attempt': 'sum',\n",
    "    'rushing_yards': 'sum',# Sum passing yards\n",
    "    'rush_touchdown': 'sum',\n",
    "    'lateral_rush': 'sum',\n",
    "    'receiving_yards': 'sum',\n",
    "    'yards_after_catch': 'sum',\n",
    "    'touchdown':'sum',\n",
    "    'fumble': 'sum',\n",
    "    'two_points': 'sum'\n",
    "\n",
    "})\n",
    "\n",
    "df_rusher_receiver_game_level[\"home\"] = df_rusher_receiver_game_level[\"home_team\"] == df_rusher_receiver_game_level.index.get_level_values(\"posteam\")\n",
    "df_rusher_receiver_game_level.drop(columns=['home_team', 'away_team'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_agg_stats(group, fields, career=True):\n",
    "    # Create a copy to avoid modifying the original\n",
    "    # df = pd.DataFrame({'game_date': group['game_date']}, index=group.index)\n",
    "    df = pd.DataFrame(index=group.index)\n",
    "    \n",
    "    # Sort chronologically\n",
    "    group_sorted = group.sort_values('game_date')\n",
    "\n",
    "    # Calculate the number of unique games for career, season, and prior season\n",
    "    if career:\n",
    "        df['n_games_career'] = range(len(group_sorted))\n",
    "\n",
    "    df['n_games_season'] = group_sorted.groupby(\n",
    "        group_sorted.index.get_level_values('season')\n",
    "    ).cumcount()\n",
    "\n",
    "    # df['n_games_prior_season'] = group_sorted.groupby(\n",
    "    #     group_sorted.index.get_level_values('season')\n",
    "    # ).transform('size').shift()\n",
    "\n",
    "\n",
    "\n",
    "    # Calculate aggregate stats\n",
    "    for field in fields:\n",
    "        if career:\n",
    "            # Career stats\n",
    "            df[f'{field}_mean_career'] = group_sorted[field].transform(lambda x: x.expanding().mean().shift())\n",
    "            df[f'{field}_total_career'] = group_sorted[field].transform(lambda x: x.expanding().sum().shift())\n",
    "        \n",
    "        # Season stats\n",
    "        df[f'{field}_mean_season'] = group_sorted.groupby([group_sorted.index.get_level_values('season')])[field].transform(lambda x: x.expanding().mean().shift())\n",
    "        df[f'{field}_total_season'] = group_sorted.groupby([group_sorted.index.get_level_values('season')])[field].transform(lambda x: x.expanding().sum().shift())\n",
    "\n",
    "        # # Prior season stats\n",
    "        # df[f'{field}_mean_prior_season'] = group_sorted.groupby([group_sorted.index.get_level_values('season') - 1])[field].transform('mean')\n",
    "        \n",
    "        # Last 5 games\n",
    "        df[f'{field}_mean_last5'] = group_sorted[field].transform(lambda x: x.rolling(window=5, min_periods=1).mean().shift())\n",
    "        df[f'{field}_total_last5'] = group_sorted[field].transform(lambda x: x.rolling(window=5, min_periods=1).sum().shift())\n",
    "        # Last Game\n",
    "        df[f'{field}_last'] = group_sorted[field].shift()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'fantasy_points'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'fantasy_points'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[200], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m fields \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfantasy_points\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreception\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrushing_yards\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtouchdown\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreceiving_yards\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfumble\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassing_yards\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpass_touchdown\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtwo_points\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Apply the function\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m df_rusher_receiver_game_level \u001b[38;5;241m=\u001b[39m df_rusher_receiver_game_level\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplayer_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplayer_id\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mapply(calc_agg_stats, fields\u001b[38;5;241m=\u001b[39mfields)\n\u001b[0;32m      7\u001b[0m df_rusher_receiver_game_level \u001b[38;5;241m=\u001b[39m df_rusher_receiver_game_level\u001b[38;5;241m.\u001b[39mreset_index(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mdrop(columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplayer_name\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplayer_id\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1824\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[1;34m(self, func, include_groups, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1822\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1823\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1824\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_apply_general(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj)\n\u001b[0;32m   1825\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1826\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, Series)\n\u001b[0;32m   1827\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1828\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1829\u001b[0m         ):\n\u001b[0;32m   1830\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1831\u001b[0m                 message\u001b[38;5;241m=\u001b[39m_apply_groupings_depr\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1832\u001b[0m                     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1835\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1836\u001b[0m             )\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1885\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[1;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   1851\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_python_apply_general\u001b[39m(\n\u001b[0;32m   1852\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1857\u001b[0m     is_agg: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1858\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1860\u001b[0m \u001b[38;5;124;03m    Apply function f in python space\u001b[39;00m\n\u001b[0;32m   1861\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1883\u001b[0m \u001b[38;5;124;03m        data after applying f\u001b[39;00m\n\u001b[0;32m   1884\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1885\u001b[0m     values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grouper\u001b[38;5;241m.\u001b[39mapply_groupwise(f, data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis)\n\u001b[0;32m   1886\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1887\u001b[0m         not_indexed_same \u001b[38;5;241m=\u001b[39m mutated\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:919\u001b[0m, in \u001b[0;36mBaseGrouper.apply_groupwise\u001b[1;34m(self, f, data, axis)\u001b[0m\n\u001b[0;32m    917\u001b[0m \u001b[38;5;66;03m# group might be modified\u001b[39;00m\n\u001b[0;32m    918\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[1;32m--> 919\u001b[0m res \u001b[38;5;241m=\u001b[39m f(group)\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[0;32m    921\u001b[0m     mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1809\u001b[0m, in \u001b[0;36mGroupBy.apply.<locals>.f\u001b[1;34m(g)\u001b[0m\n\u001b[0;32m   1807\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m   1808\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(g):\n\u001b[1;32m-> 1809\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(g, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[174], line 27\u001b[0m, in \u001b[0;36mcalc_agg_stats\u001b[1;34m(group, fields, career)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m field \u001b[38;5;129;01min\u001b[39;00m fields:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m career:\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;66;03m# Career stats\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m         df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfield\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_mean_career\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m group_sorted[field]\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mexpanding()\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mshift())\n\u001b[0;32m     28\u001b[0m         df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfield\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_total_career\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m group_sorted[field]\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mexpanding()\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mshift())\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# Season stats\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'fantasy_points'"
     ]
    }
   ],
   "source": [
    "fields = ['fantasy_points','reception','rushing_yards','touchdown','receiving_yards','fumble','passing_yards','pass_touchdown','two_points']\n",
    "\n",
    "\n",
    "# Apply the function\n",
    "df_rusher_receiver_game_level = df_rusher_receiver_game_level.groupby(['player_name', 'player_id']).apply(calc_agg_stats, fields=fields)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rusher_receiver_game_level = df_rusher_receiver_game_level.reset_index(0).reset_index(0).drop(columns = ['player_name','player_id']).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opponent Last Scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_1040\\3325812252.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  schedules_df_copy.rename(columns = {'gameday':'game_date'}, inplace = True)\n"
     ]
    }
   ],
   "source": [
    "schedules_df_copy = schedules_df[schedules_df['game_id'].isin(schedules_df['game_id'].unique()) & (schedules_df['gameday'] >= '2001-09-09')]\n",
    "schedules_df_copy.rename(columns = {'gameday':'game_date'}, inplace = True)\n",
    "\n",
    "home_teams = schedules_df_copy[['game_id', 'game_date','season','home_team','away_score','week']].copy()\n",
    "\n",
    "away_teams = schedules_df_copy[['game_id', 'game_date','season','away_team','home_score','week']].copy()\n",
    "\n",
    "home_teams.rename(columns = {'home_team':'team','away_score':'points_allowed'}, inplace = True)\n",
    "away_teams.rename(columns = {'away_team':'team','home_score':'points_allowed'}, inplace = True)\n",
    "\n",
    "points_allowed_df = pd.concat([home_teams,away_teams])\n",
    "\n",
    "points_allowed_df = points_allowed_df.groupby(['game_id', 'game_date','season','week','team']).agg({'points_allowed':'sum'})\n",
    "\n",
    "group_sorted = points_allowed_df.sort_values('week')\n",
    "\n",
    "pa_df = group_sorted.groupby(['team']).apply(calc_agg_stats, fields=['points_allowed']).reset_index(0).drop(columns = 'team').reset_index()[['game_id','game_date','season','week','team','points_allowed_mean_season','points_allowed_mean_last5']]\n",
    "\n",
    "\n",
    "pa_df.rename(columns = {'team':'opponent_team'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features from pa_df are the oppositions points allowed until a certain measure of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rusher_receiver_features = rusher_receiver_df.merge(df_rusher_receiver_game_level, how = 'inner' ,on = ['game_id','game_date','week','season','posteam','defteam','player_name','player_id'])\n",
    "rusher_receiver_features['opponent_team'] = np.where(rusher_receiver_features['team'] == rusher_receiver_features['home_team'],rusher_receiver_features['away_team'],rusher_receiver_features['home_team'])\n",
    "rusher_receiver_features = rusher_receiver_features.merge(pa_df , how = 'inner',on = ['game_date','season','week','opponent_team','game_id'])\n",
    "\n",
    "\n",
    "rusher_receiver_features = rusher_receiver_features.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last Game Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = rusher_receiver_features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Null Values in Each Column:\n",
      "game_id                      0.00%\n",
      "touchdown_total_last5        0.00%\n",
      "fumble_mean_season           0.00%\n",
      "fumble_total_career          0.00%\n",
      "fumble_mean_career           0.00%\n",
      "                             ...  \n",
      "rush_touchdown               0.00%\n",
      "rushing_yards                0.00%\n",
      "rush_attempt                 0.00%\n",
      "interception                 0.00%\n",
      "points_allowed_mean_last5    0.00%\n",
      "Length: 109, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percentage of null values in each column\n",
    "null_percentages = rusher_receiver_features.isnull().mean() * 100\n",
    "\n",
    "# Sort the percentages in descending order for better readability\n",
    "null_percentages = null_percentages.sort_values(ascending=False)\n",
    "\n",
    "# Format the output to display percentages with two decimal places\n",
    "null_percentages_formatted = null_percentages.apply(lambda x: f\"{x:.2f}%\")\n",
    "\n",
    "# Print the results\n",
    "print(\"Percentage of Null Values in Each Column:\")\n",
    "print(null_percentages_formatted)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'temp' and 'wind' are numeric\n",
    "df_combined['temp'] = pd.to_numeric(df_combined['temp'], errors='coerce')\n",
    "df_combined['wind'] = pd.to_numeric(df_combined['wind'], errors='coerce')\n",
    "\n",
    "# Calculate mean 'temp' and 'wind' by stadium\n",
    "temp_wind_means = (\n",
    "    df_combined.groupby('stadium')[['temp', 'wind']]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Merge the mean values back to the original DataFrame\n",
    "df_combined = pd.merge(\n",
    "    df_combined,\n",
    "    temp_wind_means,\n",
    "    on='stadium',\n",
    "    how='left',\n",
    "    suffixes=('', '_mean')\n",
    ")\n",
    "\n",
    "# Impute missing 'temp' and 'wind' with the group mean values\n",
    "df_combined['temp'].fillna(df_combined['temp_mean'], inplace=True)\n",
    "df_combined['wind'].fillna(df_combined['wind_mean'], inplace=True)\n",
    "\n",
    "# If any missing 'temp' or 'wind' values remain, fill them with the overall mean\n",
    "df_combined['temp'].fillna(df_combined['temp'].mean(), inplace=True)\n",
    "df_combined['wind'].fillna(df_combined['wind'].mean(), inplace=True)\n",
    "\n",
    "# Drop the temporary mean columns\n",
    "df_combined.drop(columns=['temp_mean', 'wind_mean'], inplace=True)\n",
    "\n",
    "# For the rest of the columns, fill missing values with 0\n",
    "# Exclude 'temp' and 'wind' as they've already been imputed\n",
    "columns_to_fill = df_combined.columns.difference(['temp', 'wind'])\n",
    "df_combined[columns_to_fill] = df_combined[columns_to_fill].fillna(0)\n",
    "\n",
    "# Check if any missing values remain\n",
    "remaining_nulls = df_combined.isnull().sum()\n",
    "if remaining_nulls.sum() > 0:\n",
    "    print(\"Remaining null values after imputation:\")\n",
    "    print(remaining_nulls[remaining_nulls > 0])\n",
    "else:\n",
    "    print(\"All missing values have been imputed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vars = ['home_team','away_team','spread_line',\n",
    " 'n_games_career',\n",
    " 'n_games_season',\n",
    " 'fantasy_points_mean_career',\n",
    " 'fantasy_points_total_career',\n",
    " 'fantasy_points_mean_season',\n",
    " 'fantasy_points_total_season',\n",
    " 'fantasy_points_mean_last5',\n",
    " 'fantasy_points_total_last5',\n",
    " 'fantasy_points_last',\n",
    " 'reception_mean_career',\n",
    " 'reception_total_career',\n",
    " 'reception_mean_season',\n",
    " 'reception_total_season',\n",
    " 'reception_mean_last5',\n",
    " 'reception_total_last5',\n",
    " 'reception_last',\n",
    " 'rushing_yards_mean_career',\n",
    " 'rushing_yards_total_career',\n",
    " 'rushing_yards_mean_season',\n",
    " 'rushing_yards_total_season',\n",
    " 'rushing_yards_mean_last5',\n",
    " 'rushing_yards_total_last5',\n",
    " 'rushing_yards_last',\n",
    " 'touchdown_mean_career',\n",
    " 'touchdown_total_career',\n",
    " 'touchdown_mean_season',\n",
    " 'touchdown_total_season',\n",
    " 'touchdown_mean_last5',\n",
    " 'touchdown_total_last5',\n",
    " 'touchdown_last',\n",
    " 'receiving_yards_mean_career',\n",
    " 'receiving_yards_total_career',\n",
    " 'receiving_yards_mean_season',\n",
    " 'receiving_yards_total_season',\n",
    " 'receiving_yards_mean_last5',\n",
    " 'receiving_yards_total_last5',\n",
    " 'receiving_yards_last',\n",
    " 'fumble_mean_career',\n",
    " 'fumble_total_career',\n",
    " 'fumble_mean_season',\n",
    " 'fumble_total_season',\n",
    " 'fumble_mean_last5',\n",
    " 'fumble_total_last5',\n",
    " 'fumble_last',\n",
    " 'passing_yards_mean_career',\n",
    " 'passing_yards_total_career',\n",
    " 'passing_yards_mean_season',\n",
    " 'passing_yards_total_season',\n",
    " 'passing_yards_mean_last5',\n",
    " 'passing_yards_total_last5',\n",
    " 'passing_yards_last',\n",
    " 'pass_touchdown_mean_career',\n",
    " 'pass_touchdown_total_career',\n",
    " 'pass_touchdown_mean_season',\n",
    " 'pass_touchdown_total_season',\n",
    " 'pass_touchdown_mean_last5',\n",
    " 'pass_touchdown_total_last5',\n",
    " 'pass_touchdown_last',\n",
    " 'two_points_mean_career',\n",
    " 'two_points_total_career',\n",
    " 'two_points_mean_season',\n",
    " 'two_points_total_season',\n",
    " 'two_points_mean_last5',\n",
    " 'two_points_total_last5',\n",
    " 'two_points_last',\n",
    " 'opponent_team',\n",
    " 'points_allowed_mean_season',\n",
    " 'points_allowed_mean_last5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nfl_model import NFLModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummy_variables(df, drop_first=True, dummy_na=False):\n",
    "    \"\"\"\n",
    "    Converts non-numerical columns in a DataFrame to dummy variables.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "        The input DataFrame containing the data.\n",
    "    - drop_first: bool, default=False\n",
    "        Whether to drop the first level of categorical variables to avoid the dummy variable trap.\n",
    "    - dummy_na: bool, default=False\n",
    "        Add a column to indicate NaNs, if False NaNs are ignored.\n",
    "\n",
    "    Returns:\n",
    "    - df_dummies: pandas DataFrame\n",
    "        The DataFrame with non-numeric columns converted to dummy variables.\n",
    "    \"\"\"\n",
    "    # Identify non-numeric columns\n",
    "    non_numeric_cols = df.select_dtypes(exclude=['number', 'bool']).columns.tolist()\n",
    "\n",
    "    # If there are no non-numeric columns, return the original DataFrame\n",
    "    if not non_numeric_cols:\n",
    "        print(\"No non-numerical columns to convert.\")\n",
    "        return df.copy()\n",
    "\n",
    "    # Convert categorical variables to dummy variables\n",
    "    df_dummies = pd.get_dummies(df, columns=non_numeric_cols, drop_first=drop_first, dummy_na=dummy_na)\n",
    "\n",
    "    return df_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_include = df_combined.columns.difference(['game_id', 'game_date', 'player_name'])\n",
    "final_df = df_combined[x_vars + ['fantasy_points']].copy()\n",
    "# final_df['player_id'] = final_df['player_id'].astype('category')\n",
    "final_df = get_dummy_variables(final_df)\n",
    "\n",
    "y_var = 'fantasy_points'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing completed.\n",
      "Lasso selected features: ['n_games_career', 'n_games_season', 'fantasy_points_total_season', 'fantasy_points_total_last5', 'reception_mean_career', 'reception_mean_season', 'reception_total_season', 'reception_mean_last5', 'reception_total_last5', 'reception_last', 'rushing_yards_last', 'touchdown_total_career', 'touchdown_total_season', 'receiving_yards_mean_career', 'receiving_yards_total_career', 'receiving_yards_total_last5', 'fumble_mean_career', 'fumble_total_last5', 'passing_yards_mean_career', 'pass_touchdown_total_career', 'two_points_mean_last5', 'points_allowed_mean_season', 'home_team_TEN', 'away_team_NE', 'away_team_NYJ', 'opponent_team_BUF', 'opponent_team_DET']\n",
      "Elastic Net selected features: ['spread_line', 'n_games_career', 'n_games_season', 'fantasy_points_mean_career', 'fantasy_points_total_career', 'fantasy_points_total_season', 'fantasy_points_total_last5', 'reception_mean_career', 'reception_mean_season', 'reception_total_season', 'reception_mean_last5', 'reception_total_last5', 'reception_last', 'rushing_yards_mean_season', 'rushing_yards_last', 'touchdown_total_career', 'touchdown_total_season', 'touchdown_total_last5', 'receiving_yards_mean_career', 'receiving_yards_total_career', 'receiving_yards_mean_season', 'receiving_yards_total_season', 'receiving_yards_mean_last5', 'receiving_yards_total_last5', 'fumble_mean_career', 'fumble_total_last5', 'passing_yards_mean_career', 'passing_yards_total_career', 'passing_yards_mean_season', 'passing_yards_total_season', 'passing_yards_mean_last5', 'passing_yards_total_last5', 'pass_touchdown_total_career', 'two_points_mean_career', 'two_points_total_career', 'two_points_mean_last5', 'two_points_total_last5', 'points_allowed_mean_season', 'points_allowed_mean_last5', 'home_team_BAL', 'home_team_CHI', 'home_team_CIN', 'home_team_CLE', 'home_team_GB', 'home_team_KC', 'home_team_LA', 'home_team_LV', 'home_team_MIA', 'home_team_NYG', 'home_team_SEA', 'home_team_TB', 'home_team_TEN', 'away_team_ATL', 'away_team_CAR', 'away_team_CHI', 'away_team_DET', 'away_team_GB', 'away_team_IND', 'away_team_KC', 'away_team_MIA', 'away_team_MIN', 'away_team_NE', 'away_team_NYJ', 'away_team_PIT', 'away_team_SF', 'away_team_TEN', 'opponent_team_BAL', 'opponent_team_BUF', 'opponent_team_CAR', 'opponent_team_CIN', 'opponent_team_DEN', 'opponent_team_DET', 'opponent_team_NE', 'opponent_team_NO', 'opponent_team_PIT', 'opponent_team_SF', 'opponent_team_TB', 'opponent_team_TEN']\n",
      "Model evaluation completed.\n",
      "       Method              Model       MAE        MSE        R2\n",
      "0       Lasso  Linear Regression  5.451069  57.137105  0.293848\n",
      "1       Lasso      Random Forest  5.547412  59.540520  0.264145\n",
      "2  ElasticNet  Linear Regression  5.453217  57.060455  0.294796\n",
      "3  ElasticNet      Random Forest  5.502499  59.022144  0.270551\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = NFLModel(data=final_df, target_variable=y_var)\n",
    "\n",
    "# Preprocess data\n",
    "model.preprocess_data()\n",
    "\n",
    "# Perform feature selection\n",
    "model.feature_selection()\n",
    "\n",
    "# Evaluate models\n",
    "model.evaluate_models()\n",
    "\n",
    "# Get and print the results\n",
    "results_df = model.get_results()\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.glassbox import ExplainableBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_Vars = [x for x in list(final_df.columns) if x != y_var]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "            final_df[final_Vars], final_df[y_var], test_size= .2, random_state=1082\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ExplainableBoostingRegressor(max_bins=40, reg_alpha=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExplainableBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>ExplainableBoostingRegressor(max_bins=40, reg_alpha=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ExplainableBoostingRegressor(max_bins=40, reg_alpha=1)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebm = ExplainableBoostingRegressor(max_bins = 40, reg_alpha = 1)\n",
    "\n",
    "\n",
    "ebm.fit(X_train_raw,y_train)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 5.44361484638693\n",
      "MSE: 58.2249309925513\n"
     ]
    }
   ],
   "source": [
    "preds = ebm.predict(X_test_raw)\n",
    "\n",
    "# preds_df['actual'] = y_test['fantasy_points']\n",
    "\n",
    "\n",
    "\n",
    "print(\"MAE: \" + str(mean_absolute_error(preds, y_test)))\n",
    "\n",
    "print(\"MSE: \" + str(mean_squared_error(preds, y_test)))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
