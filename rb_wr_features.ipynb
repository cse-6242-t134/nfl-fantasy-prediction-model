{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nfl_data_py as nfl\n",
    "import datetime as dt\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Suppress FutureWarnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background/Ideas\n",
    "\n",
    "- Features will be based off seasonal,weekly,career, and last 5 based values\n",
    "- Idea is that certain players which can be differentiated by career based values paired with weekly performance and or seasonal (team strength proxy) can be paired to build something relatively predictive.\n",
    "- Interactivity can be dependent on clicking and choosing assortment of players and identifying/projecting current projections.\n",
    "- Data seems to get updated weekly so these predictions would change over time as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "This section focuses on pulling the data and prepping/aggregating the dependent variable. (Fantasy Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024 done.\n",
      "2023 done.\n",
      "2022 done.\n",
      "2021 done.\n",
      "2020 done.\n",
      "2019 done.\n",
      "2018 done.\n",
      "2017 done.\n",
      "2016 done.\n",
      "2015 done.\n",
      "2014 done.\n",
      "2013 done.\n",
      "2012 done.\n",
      "2011 done.\n",
      "2010 done.\n",
      "2009 done.\n",
      "2008 done.\n",
      "2007 done.\n",
      "2006 done.\n",
      "2005 done.\n",
      "2004 done.\n",
      "2003 done.\n",
      "2002 done.\n",
      "2001 done.\n",
      "2000 done.\n",
      "1999 done.\n",
      "Downcasting floats.\n",
      "Downcasting floats.\n"
     ]
    }
   ],
   "source": [
    "roster_data = nfl.import_seasonal_rosters([2024,2023,2022,2021,2020,2019,2018,2017,2016,2015,2014,2013,2012,2011,2010,2009,2008,2007,2006,2005,2004,2003,2002,2001,2000,1999])\n",
    "pbp_df = pd.DataFrame(nfl.import_pbp_data([2024,2023,2022,2021,2020,2019,2018,2017,2016,2015,2014,2013,2012,2011,2010,2009,2008,2007,2006,2005,2004,2003,2002,2001,2000,1999]))\n",
    "weekly_df = pd.DataFrame(nfl.import_weekly_data([2024,2023,2022,2021,2020,2019,2018,2017,2016,2015,2014,2013,2012,2011,2010,2009,2008,2007,2006,2005,2004,2003,2002,2001,2000,1999]))\n",
    "# injuries_df = pd.DataFrame(nfl.import_injuries([2024,2023,2022,2021,2020,2019,2018,2017,2016,2015,2014,2013,2012,2011,2010,2009,2008,2007,2006,2005,2004,2003,2002,2001,2000]))\n",
    "schedules_df = pd.DataFrame(nfl.import_schedules([2024,2023,2022,2021,2020,2019,2018,2017,2016,2015,2014,2013,2012,2011,2010,2009,2008,2007,2006,2005,2004,2003,2002,2001,2000,1999]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Data Transformations\n",
    "\n",
    "- Getting General RB and WR stats and creating complete dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_1040\\3887360229.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  receiver_rusher_stats['two_points'] = np.where(receiver_rusher_stats['two_point_conv_result'] == 'success',1,0)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_1040\\3887360229.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  receiver_rusher_stats['two_points'] = np.where(receiver_rusher_stats['two_point_conv_result'] == 'success',1,0)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_1040\\3887360229.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  receiver_rusher_stats.rename(columns = {'complete_pass':'reception'},inplace = True)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_1040\\3887360229.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  team['team'] = team['team'].replace({'OAK':'LV', 'STL':'LA', 'SD':'LAC','HST':'HOU', 'BLT':'BAL', 'CLV':'CLE','SL':'LA','ARZ':'ARI'})\n"
     ]
    }
   ],
   "source": [
    "## Basic PBP Passing Stats\n",
    "\n",
    "def get_opposing_team(df):\n",
    "    if df['home_team'] == df['team']:\n",
    "        val = df['away_team']\n",
    "    elif df['away_team'] == df['team']:\n",
    "        val = df['home_team']\n",
    "    else:\n",
    "        val = None\n",
    "\n",
    "    return val\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# team = roster_data[roster_data['depth_chart_position'].isin(['RB','WR'])][['season','player_id','team','depth_chart_position']]\n",
    "\n",
    "team = roster_data[['season','player_id','team','depth_chart_position']]\n",
    "\n",
    "receiver_rusher_stats =  pbp_df[(pbp_df['receiver_player_id'].notnull()) | (pbp_df['rusher_player_id'].notnull())]\n",
    "                         \n",
    "\n",
    "receiver_rusher_stats['two_points'] = np.where(receiver_rusher_stats['two_point_conv_result'] == 'success',1,0)\n",
    "                         \n",
    "receiver_rusher_stats.rename(columns = {'complete_pass':'reception'},inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "receiver_stats= receiver_rusher_stats.groupby(['game_id', 'game_date', 'week','div_game','posteam','defteam', 'home_team', 'away_team', 'weather', 'stadium',  'spread_line', 'total_line', 'roof', 'surface', 'temp', 'wind', 'home_coach', 'away_coach', 'receiver_player_id', 'receiver_player_name','season']).agg({\n",
    "    'passing_yards': 'sum',\n",
    "    'air_yards': 'sum',\n",
    "    'pass_touchdown': 'sum', \n",
    "    'pass_attempt': 'sum',\n",
    "    'reception': 'sum',\n",
    "    'interception': 'sum', #the passing stats are duplicated for receivers\n",
    "    'rush_attempt': 'sum',\n",
    "    'rushing_yards': 'sum',# Sum passing yards\n",
    "    'rush_touchdown': 'sum',\n",
    "    'lateral_rush': 'sum',\n",
    "    'receiving_yards': 'sum',\n",
    "    'yards_after_catch':'sum',\n",
    "    'touchdown':'sum',\n",
    "    'fumble': 'sum',\n",
    "    'two_points': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "rushing_stats = receiver_rusher_stats.groupby(['game_id', 'game_date', 'week', 'div_game','posteam','defteam', 'home_team', 'away_team', 'weather', 'stadium',  'spread_line', 'total_line', 'roof', 'surface', 'temp', 'wind', 'home_coach', 'away_coach', 'rusher_player_id', 'rusher_player_name','season']).agg({\n",
    "    'passing_yards': 'sum',\n",
    "    'air_yards': 'sum',\n",
    "    'pass_touchdown': 'sum', \n",
    "    'pass_attempt': 'sum',\n",
    "    'reception': 'sum',\n",
    "    'interception': 'sum',\n",
    "    'rush_attempt': 'sum',\n",
    "    'rushing_yards': 'sum',# Sum passing yards\n",
    "    'rush_touchdown': 'sum',\n",
    "    'lateral_rush': 'sum',\n",
    "    'receiving_yards': 'sum',\n",
    "    'yards_after_catch': 'sum',\n",
    "    'touchdown':'sum',\n",
    "    'fumble': 'sum',\n",
    "    'two_points': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "## Grabbing seasonal info\n",
    "\n",
    "\n",
    "team['team'] = team['team'].replace({'OAK':'LV', 'STL':'LA', 'SD':'LAC','HST':'HOU', 'BLT':'BAL', 'CLV':'CLE','SL':'LA','ARZ':'ARI'})\n",
    "\n",
    "\n",
    "# team.rename(columns = {'player_id':'passer_player_id'},inplace = True)\n",
    "\n",
    "## Standardizing Columns\n",
    "rushing_stats.rename(columns = {'rusher_player_id':'player_id'}, inplace = True)\n",
    "\n",
    "receiver_stats.rename(columns = {'receiver_player_id':'player_id'}, inplace = True)\n",
    "\n",
    "rushing_stats.rename(columns = {'rusher_player_name':'player_name'}, inplace = True)\n",
    "\n",
    "receiver_stats.rename(columns = {'receiver_player_name':'player_name'}, inplace = True)\n",
    "\n",
    "\n",
    "rusher_receiver_df = pd.concat([receiver_stats,rushing_stats])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# rusher_receiver_df = rusher_receiver_df.merge(team, on = ['player_id','season'], how = 'inner')\n",
    "\n",
    "\n",
    "## Aggregate average score to opposition \n",
    "\n",
    "# rusher_receiver_df['opponent_team'] = rusher_receiver_df.apply(get_opposing_team,axis = 1)\n",
    "\n",
    "# print('Number Missing Opponent:' + str(rusher_receiver_df[rusher_receiver_df['opponent_team'].isna()].shape[0]))\n",
    "# rusher_receiver_df = rusher_receiver_df[~rusher_receiver_df['opponent_team'].isna()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "game_score_info = schedules_df[['season','home_score','away_score','game_id']].copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rusher_receiver_df = rusher_receiver_df.merge(game_score_info, on = ['game_id','season'], how = 'inner')\n",
    "\n",
    "# rusher_receiver_df.rename(columns = {'defteam':'opponent_team'}, inplace = True)\n",
    "\n",
    "\n",
    "# rusher_receiver_df = rusher_receiver_df.groupby(['game_id', 'game_date', 'week', 'div_game', 'posteam','defteam','home_team', 'away_team', 'weather', 'stadium',  'spread_line', 'total_line', 'roof', 'surface', 'temp', 'wind', 'home_coach', 'away_coach', 'player_id', 'player_name','season','home_score','away_score','team','depth_chart_position','opponent_team']).agg({\n",
    "#     'passing_yards': 'sum',\n",
    "#     'air_yards': 'sum',\n",
    "#     'pass_touchdown': 'sum', \n",
    "#     'pass_attempt': 'sum',\n",
    "#     'reception': 'sum',\n",
    "#     'interception': 'sum',\n",
    "#     'rush_attempt': 'sum',\n",
    "#     'rushing_yards': 'sum',# Sum passing yards\n",
    "#     'rush_touchdown': 'sum',\n",
    "#     'lateral_rush': 'sum',\n",
    "#     'receiving_yards': 'sum',\n",
    "#     'yards_after_catch': 'sum',\n",
    "#     'touchdown':'sum',\n",
    "#     'fumble': 'sum',\n",
    "#     'two_points': 'sum'\n",
    "# }).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "rusher_receiver_df = rusher_receiver_df.groupby(['game_id', 'game_date', 'week', 'div_game', 'posteam','defteam','home_team', 'away_team', 'weather', 'stadium',  'spread_line', 'total_line', 'roof', 'surface', 'temp', 'wind', 'home_coach', 'away_coach', 'player_id', 'player_name','season']).agg({\n",
    "    'passing_yards': 'sum',\n",
    "    'air_yards': 'sum',\n",
    "    'pass_touchdown': 'sum', \n",
    "    'pass_attempt': 'sum',\n",
    "    'reception': 'sum',\n",
    "    'interception': 'sum',\n",
    "    'rush_attempt': 'sum',\n",
    "    'rushing_yards': 'sum',# Sum passing yards\n",
    "    'rush_touchdown': 'sum',\n",
    "    'lateral_rush': 'sum',\n",
    "    'receiving_yards': 'sum',\n",
    "    'yards_after_catch': 'sum',\n",
    "    'touchdown':'sum',\n",
    "    'fumble': 'sum',\n",
    "    'two_points': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "rusher_receiver_df.rename(columns = {'defteam':'opponent_team'} , inplace = True )\n",
    "\n",
    "\n",
    "# #Checking the passing stats dataframe\n",
    "# rusher_receiver_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84781, 36)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rusher_receiver_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Fantasy Points Column\n",
    "\n",
    "\n",
    "Offensive Players:\n",
    "\n",
    "- Passing Yards: 1 point per 25 yards\n",
    "- Passing Touchdowns: 4 points\n",
    "- Passing Interceptions: -2 points\n",
    "- Rushing Yards: 1 point per 10 yards\n",
    "- Rushing Touchdowns: 6 points\n",
    "- Receptions: 1 points (only if using PPR scoring)\n",
    "- Receiving Yards: 1 point per 10 yards\n",
    "- Receiving Touchdowns: 6 points\n",
    "- 2-Point Conversions: 2 points\n",
    "- Fumbles Lost: -2 points\n",
    "- Fumble Recovered for a Touchdown: 6 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "rusher_receiver_df['fantasy_points'] = ((rusher_receiver_df['passing_yards']/25 )\n",
    "                                         + (rusher_receiver_df['pass_touchdown'] * 4) + \n",
    "                                         (rusher_receiver_df['interception'] * -2) +\n",
    "                                         (rusher_receiver_df['reception'] * 1) +\n",
    "                                         (rusher_receiver_df['touchdown'] * 6) +\n",
    "                                         (rusher_receiver_df['receiving_yards'] * .1) +\n",
    "                                         (rusher_receiver_df['fumble'] * -2) +\n",
    "                                         (rusher_receiver_df['two_points'] * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8.12\n",
       "1    0.00\n",
       "2    4.80\n",
       "3    1.14\n",
       "4    0.00\n",
       "Name: fantasy_points, dtype: float64"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rusher_receiver_df.head(5)['fantasy_points']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_rusher_receiver_game_level = rusher_receiver_df.groupby(['game_id', 'game_date', 'week', 'season', 'posteam', 'opponent_team', 'player_name', 'player_id']).agg({\n",
    "    # Game level\n",
    "    'home_team': 'first',\n",
    "    'away_team': 'first',\n",
    "\n",
    "    # Play level\n",
    "    'fantasy_points': 'sum',\n",
    "    'passing_yards': 'sum',\n",
    "    'air_yards': 'sum',\n",
    "    'pass_touchdown': 'sum', \n",
    "    'pass_attempt': 'sum',\n",
    "    'reception': 'sum',\n",
    "    'interception': 'sum',\n",
    "    'rush_attempt': 'sum',\n",
    "    'rushing_yards': 'sum',# Sum passing yards\n",
    "    'rush_touchdown': 'sum',\n",
    "    'lateral_rush': 'sum',\n",
    "    'receiving_yards': 'sum',\n",
    "    'yards_after_catch': 'sum',\n",
    "    'touchdown':'sum',\n",
    "    'fumble': 'sum',\n",
    "    'two_points': 'sum'\n",
    "\n",
    "})\n",
    "\n",
    "df_rusher_receiver_game_level[\"home\"] = df_rusher_receiver_game_level[\"home_team\"] == df_rusher_receiver_game_level.index.get_level_values(\"posteam\")\n",
    "df_rusher_receiver_game_level.drop(columns=['home_team', 'away_team'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_agg_stats(group, fields, career=True):\n",
    "    # Create a copy to avoid modifying the original\n",
    "    # df = pd.DataFrame({'game_date': group['game_date']}, index=group.index)\n",
    "    df = pd.DataFrame(index=group.index)\n",
    "    \n",
    "    # Sort chronologically\n",
    "    group_sorted = group.sort_values('game_date')\n",
    "\n",
    "    # Calculate the number of unique games for career, season, and prior season\n",
    "    if career:\n",
    "        df['n_games_career'] = range(len(group_sorted))\n",
    "\n",
    "    df['n_games_season'] = group_sorted.groupby(\n",
    "        group_sorted.index.get_level_values('season')\n",
    "    ).cumcount()\n",
    "\n",
    "    # df['n_games_prior_season'] = group_sorted.groupby(\n",
    "    #     group_sorted.index.get_level_values('season')\n",
    "    # ).transform('size').shift()\n",
    "\n",
    "\n",
    "\n",
    "    # Calculate aggregate stats\n",
    "    for field in fields:\n",
    "        if career:\n",
    "            # Career stats\n",
    "            df[f'{field}_mean_career'] = group_sorted[field].transform(lambda x: x.expanding().mean().shift())\n",
    "            df[f'{field}_total_career'] = group_sorted[field].transform(lambda x: x.expanding().sum().shift())\n",
    "        \n",
    "        # Season stats\n",
    "        df[f'{field}_mean_season'] = group_sorted.groupby([group_sorted.index.get_level_values('season')])[field].transform(lambda x: x.expanding().mean().shift())\n",
    "        df[f'{field}_total_season'] = group_sorted.groupby([group_sorted.index.get_level_values('season')])[field].transform(lambda x: x.expanding().sum().shift())\n",
    "\n",
    "        # # Prior season stats\n",
    "        # df[f'{field}_mean_prior_season'] = group_sorted.groupby([group_sorted.index.get_level_values('season') - 1])[field].transform('mean')\n",
    "        \n",
    "        # Last 5 games\n",
    "        df[f'{field}_mean_last5'] = group_sorted[field].transform(lambda x: x.rolling(window=5, min_periods=1).mean().shift())\n",
    "        df[f'{field}_total_last5'] = group_sorted[field].transform(lambda x: x.rolling(window=5, min_periods=1).sum().shift())\n",
    "        # Last Game\n",
    "        df[f'{field}_last'] = group_sorted[field].shift()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['fantasy_points','reception','rushing_yards','touchdown','receiving_yards','fumble','passing_yards','pass_touchdown','two_points']\n",
    "\n",
    "\n",
    "# Apply the function\n",
    "df_rusher_receiver_game_level = df_rusher_receiver_game_level.groupby(['player_name', 'player_id']).apply(calc_agg_stats, fields=fields)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rusher_receiver_game_level = df_rusher_receiver_game_level.reset_index(0).reset_index(0).drop(columns = ['player_name','player_id']).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opponent Last Scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_1040\\3325812252.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  schedules_df_copy.rename(columns = {'gameday':'game_date'}, inplace = True)\n"
     ]
    }
   ],
   "source": [
    "schedules_df_copy = schedules_df[schedules_df['game_id'].isin(schedules_df['game_id'].unique()) & (schedules_df['gameday'] >= '2001-09-09')]\n",
    "schedules_df_copy.rename(columns = {'gameday':'game_date'}, inplace = True)\n",
    "\n",
    "home_teams = schedules_df_copy[['game_id', 'game_date','season','home_team','away_score','week']].copy()\n",
    "\n",
    "away_teams = schedules_df_copy[['game_id', 'game_date','season','away_team','home_score','week']].copy()\n",
    "\n",
    "home_teams.rename(columns = {'home_team':'team','away_score':'points_allowed'}, inplace = True)\n",
    "away_teams.rename(columns = {'away_team':'team','home_score':'points_allowed'}, inplace = True)\n",
    "\n",
    "points_allowed_df = pd.concat([home_teams,away_teams])\n",
    "\n",
    "points_allowed_df = points_allowed_df.groupby(['game_id', 'game_date','season','week','team']).agg({'points_allowed':'sum'})\n",
    "\n",
    "group_sorted = points_allowed_df.sort_values('week')\n",
    "\n",
    "pa_df = group_sorted.groupby(['team']).apply(calc_agg_stats, fields=['points_allowed']).reset_index(0).drop(columns = 'team').reset_index()[['game_id','game_date','season','week','team','points_allowed_mean_season','points_allowed_mean_last5']]\n",
    "\n",
    "\n",
    "pa_df.rename(columns = {'team':'opponent_team'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features from pa_df are the oppositions points allowed until a certain measure of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rusher_receiver_features = rusher_receiver_df.merge(df_rusher_receiver_game_level, how = 'inner' ,on = ['game_id','game_date','week','season','posteam','opponent_team','player_name','player_id'])\n",
    "# rusher_receiver_features['opponent_team'] = np.where(rusher_receiver_features['team'] == rusher_receiver_features['home_team'],rusher_receiver_features['away_team'],rusher_receiver_features['home_team'])\n",
    "rusher_receiver_features = rusher_receiver_features.merge(pa_df , how = 'inner',on = ['game_date','season','week','opponent_team','game_id'])\n",
    "\n",
    "\n",
    "rusher_receiver_features = rusher_receiver_features.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last Game Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78976, 104)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rusher_receiver_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = rusher_receiver_features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Null Values in Each Column:\n",
      "game_id                      0.00%\n",
      "game_date                    0.00%\n",
      "fumble_mean_season           0.00%\n",
      "fumble_total_career          0.00%\n",
      "fumble_mean_career           0.00%\n",
      "                             ...  \n",
      "receiving_yards              0.00%\n",
      "lateral_rush                 0.00%\n",
      "rush_touchdown               0.00%\n",
      "rushing_yards                0.00%\n",
      "points_allowed_mean_last5    0.00%\n",
      "Length: 104, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percentage of null values in each column\n",
    "null_percentages = rusher_receiver_features.isnull().mean() * 100\n",
    "\n",
    "# Sort the percentages in descending order for better readability\n",
    "null_percentages = null_percentages.sort_values(ascending=False)\n",
    "\n",
    "# Format the output to display percentages with two decimal places\n",
    "null_percentages_formatted = null_percentages.apply(lambda x: f\"{x:.2f}%\")\n",
    "\n",
    "# Print the results\n",
    "print(\"Percentage of Null Values in Each Column:\")\n",
    "print(null_percentages_formatted)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'temp' and 'wind' are numeric\n",
    "df_combined['temp'] = pd.to_numeric(df_combined['temp'], errors='coerce')\n",
    "df_combined['wind'] = pd.to_numeric(df_combined['wind'], errors='coerce')\n",
    "\n",
    "# Calculate mean 'temp' and 'wind' by stadium\n",
    "temp_wind_means = (\n",
    "    df_combined.groupby('stadium')[['temp', 'wind']]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Merge the mean values back to the original DataFrame\n",
    "df_combined = pd.merge(\n",
    "    df_combined,\n",
    "    temp_wind_means,\n",
    "    on='stadium',\n",
    "    how='left',\n",
    "    suffixes=('', '_mean')\n",
    ")\n",
    "\n",
    "# Impute missing 'temp' and 'wind' with the group mean values\n",
    "df_combined['temp'].fillna(df_combined['temp_mean'], inplace=True)\n",
    "df_combined['wind'].fillna(df_combined['wind_mean'], inplace=True)\n",
    "\n",
    "# If any missing 'temp' or 'wind' values remain, fill them with the overall mean\n",
    "df_combined['temp'].fillna(df_combined['temp'].mean(), inplace=True)\n",
    "df_combined['wind'].fillna(df_combined['wind'].mean(), inplace=True)\n",
    "\n",
    "# Drop the temporary mean columns\n",
    "df_combined.drop(columns=['temp_mean', 'wind_mean'], inplace=True)\n",
    "\n",
    "# For the rest of the columns, fill missing values with 0\n",
    "# Exclude 'temp' and 'wind' as they've already been imputed\n",
    "columns_to_fill = df_combined.columns.difference(['temp', 'wind'])\n",
    "df_combined[columns_to_fill] = df_combined[columns_to_fill].fillna(0)\n",
    "\n",
    "# Check if any missing values remain\n",
    "remaining_nulls = df_combined.isnull().sum()\n",
    "if remaining_nulls.sum() > 0:\n",
    "    print(\"Remaining null values after imputation:\")\n",
    "    print(remaining_nulls[remaining_nulls > 0])\n",
    "else:\n",
    "    print(\"All missing values have been imputed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vars = ['home_team','away_team','spread_line',\n",
    " 'n_games_career',\n",
    " 'n_games_season',\n",
    " 'fantasy_points_mean_career',\n",
    " 'fantasy_points_total_career',\n",
    " 'fantasy_points_mean_season',\n",
    " 'fantasy_points_total_season',\n",
    " 'fantasy_points_mean_last5',\n",
    " 'fantasy_points_total_last5',\n",
    " 'fantasy_points_last',\n",
    " 'reception_mean_career',\n",
    " 'reception_total_career',\n",
    " 'reception_mean_season',\n",
    " 'reception_total_season',\n",
    " 'reception_mean_last5',\n",
    " 'reception_total_last5',\n",
    " 'reception_last',\n",
    " 'rushing_yards_mean_career',\n",
    " 'rushing_yards_total_career',\n",
    " 'rushing_yards_mean_season',\n",
    " 'rushing_yards_total_season',\n",
    " 'rushing_yards_mean_last5',\n",
    " 'rushing_yards_total_last5',\n",
    " 'rushing_yards_last',\n",
    " 'touchdown_mean_career',\n",
    " 'touchdown_total_career',\n",
    " 'touchdown_mean_season',\n",
    " 'touchdown_total_season',\n",
    " 'touchdown_mean_last5',\n",
    " 'touchdown_total_last5',\n",
    " 'touchdown_last',\n",
    " 'receiving_yards_mean_career',\n",
    " 'receiving_yards_total_career',\n",
    " 'receiving_yards_mean_season',\n",
    " 'receiving_yards_total_season',\n",
    " 'receiving_yards_mean_last5',\n",
    " 'receiving_yards_total_last5',\n",
    " 'receiving_yards_last',\n",
    " 'fumble_mean_career',\n",
    " 'fumble_total_career',\n",
    " 'fumble_mean_season',\n",
    " 'fumble_total_season',\n",
    " 'fumble_mean_last5',\n",
    " 'fumble_total_last5',\n",
    " 'fumble_last',\n",
    " 'passing_yards_mean_career',\n",
    " 'passing_yards_total_career',\n",
    " 'passing_yards_mean_season',\n",
    " 'passing_yards_total_season',\n",
    " 'passing_yards_mean_last5',\n",
    " 'passing_yards_total_last5',\n",
    " 'passing_yards_last',\n",
    " 'pass_touchdown_mean_career',\n",
    " 'pass_touchdown_total_career',\n",
    " 'pass_touchdown_mean_season',\n",
    " 'pass_touchdown_total_season',\n",
    " 'pass_touchdown_mean_last5',\n",
    " 'pass_touchdown_total_last5',\n",
    " 'pass_touchdown_last',\n",
    " 'two_points_mean_career',\n",
    " 'two_points_total_career',\n",
    " 'two_points_mean_season',\n",
    " 'two_points_total_season',\n",
    " 'two_points_mean_last5',\n",
    " 'two_points_total_last5',\n",
    " 'two_points_last',\n",
    " 'opponent_team',\n",
    " 'points_allowed_mean_season',\n",
    " 'points_allowed_mean_last5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nfl_model import NFLModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummy_variables(df, drop_first=True, dummy_na=False):\n",
    "    \"\"\"\n",
    "    Converts non-numerical columns in a DataFrame to dummy variables.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "        The input DataFrame containing the data.\n",
    "    - drop_first: bool, default=False\n",
    "        Whether to drop the first level of categorical variables to avoid the dummy variable trap.\n",
    "    - dummy_na: bool, default=False\n",
    "        Add a column to indicate NaNs, if False NaNs are ignored.\n",
    "\n",
    "    Returns:\n",
    "    - df_dummies: pandas DataFrame\n",
    "        The DataFrame with non-numeric columns converted to dummy variables.\n",
    "    \"\"\"\n",
    "    # Identify non-numeric columns\n",
    "    non_numeric_cols = df.select_dtypes(exclude=['number', 'bool']).columns.tolist()\n",
    "\n",
    "    # If there are no non-numeric columns, return the original DataFrame\n",
    "    if not non_numeric_cols:\n",
    "        print(\"No non-numerical columns to convert.\")\n",
    "        return df.copy()\n",
    "\n",
    "    # Convert categorical variables to dummy variables\n",
    "    df_dummies = pd.get_dummies(df, columns=non_numeric_cols, drop_first=drop_first, dummy_na=dummy_na)\n",
    "\n",
    "    return df_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['home_team', 'away_team', 'opponent_team'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[333], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# columns_to_include = df_combined.columns.difference(['game_id', 'game_date', 'player_name'])\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# final_df = df_combined[x_vars + ['fantasy_points']].copy()\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# final_df['player_id'] = final_df['player_id'].astype('category')\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m final_df \u001b[38;5;241m=\u001b[39m get_dummy_variables(final_df[x_vars])\n\u001b[0;32m      6\u001b[0m y_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfantasy_points\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['home_team', 'away_team', 'opponent_team'] not in index\""
     ]
    }
   ],
   "source": [
    "columns_to_include = df_combined.columns.difference(['game_id', 'game_date', 'player_name'])\n",
    "final_df = df_combined[x_vars + ['fantasy_points']].copy()\n",
    "# final_df['player_id'] = final_df['player_id'].astype('category')\n",
    "final_df = get_dummy_variables(final_df)\n",
    "\n",
    "y_var = 'fantasy_points'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing completed.\n",
      "Lasso selected features: ['n_games_career', 'n_games_season', 'fantasy_points_mean_career', 'fantasy_points_total_season', 'fantasy_points_total_last5', 'reception_mean_season', 'reception_mean_last5', 'reception_total_last5', 'reception_last', 'rushing_yards_mean_season', 'rushing_yards_last', 'touchdown_total_season', 'receiving_yards_mean_career', 'receiving_yards_total_last5', 'fumble_mean_career', 'passing_yards_mean_career', 'pass_touchdown_total_career', 'two_points_total_career', 'points_allowed_mean_last5', 'opponent_team_DET', 'opponent_team_TEN']\n",
      "Elastic Net selected features: ['n_games_career', 'n_games_season', 'fantasy_points_mean_career', 'fantasy_points_total_career', 'fantasy_points_mean_season', 'fantasy_points_total_season', 'fantasy_points_total_last5', 'reception_mean_career', 'reception_mean_season', 'reception_total_season', 'reception_mean_last5', 'reception_total_last5', 'reception_last', 'rushing_yards_mean_season', 'rushing_yards_last', 'touchdown_total_career', 'touchdown_total_season', 'touchdown_total_last5', 'receiving_yards_mean_career', 'receiving_yards_total_career', 'receiving_yards_mean_season', 'receiving_yards_total_season', 'receiving_yards_mean_last5', 'receiving_yards_total_last5', 'fumble_mean_career', 'passing_yards_mean_career', 'passing_yards_total_career', 'passing_yards_mean_season', 'passing_yards_total_season', 'passing_yards_mean_last5', 'passing_yards_total_last5', 'pass_touchdown_mean_career', 'pass_touchdown_total_career', 'two_points_total_career', 'points_allowed_mean_season', 'points_allowed_mean_last5', 'home_team_BAL', 'home_team_BUF', 'home_team_GB', 'home_team_TEN', 'away_team_CHI', 'away_team_DET', 'away_team_GB', 'away_team_IND', 'away_team_NE', 'away_team_NYJ', 'away_team_PIT', 'away_team_SF', 'away_team_WAS', 'opponent_team_BAL', 'opponent_team_BUF', 'opponent_team_CAR', 'opponent_team_CIN', 'opponent_team_DEN', 'opponent_team_DET', 'opponent_team_KC', 'opponent_team_LV', 'opponent_team_PIT', 'opponent_team_TEN']\n",
      "Model evaluation completed.\n",
      "       Method              Model       MAE        MSE        R2\n",
      "0       Lasso  Linear Regression  5.328568  56.059157  0.302248\n",
      "1       Lasso      Random Forest  5.443364  58.344400  0.273805\n",
      "2  ElasticNet  Linear Regression  5.324680  55.990394  0.303104\n",
      "3  ElasticNet      Random Forest  5.415623  57.888099  0.279484\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = NFLModel(data=final_df, target_variable=y_var)\n",
    "\n",
    "# Preprocess data\n",
    "model.preprocess_data()\n",
    "\n",
    "# Perform feature selection\n",
    "model.feature_selection()\n",
    "\n",
    "# Evaluate models\n",
    "model.evaluate_models()\n",
    "\n",
    "# Get and print the results\n",
    "results_df = model.get_results()\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoreout Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def preprocess_data(data,target_variable):\n",
    "        \"\"\"\n",
    "        Preprocesses the data by splitting into training and testing sets,\n",
    "        converting categorical variables to dummy variables, and scaling the features.\n",
    "        \"\"\"\n",
    "        # Separate features and target\n",
    "        X = data.drop(columns=[target_variable])\n",
    "        y = data[target_variable]\n",
    "\n",
    "        # Split data into training and testing sets\n",
    "        X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=.2, random_state= 42\n",
    "        )\n",
    "\n",
    "        # Align the training and testing data\n",
    "        X_train, X_test = X_train_raw.align(X_test_raw, join='left', axis=1, fill_value=0)\n",
    "\n",
    "        # Convert y_train and y_test to 1D arrays if necessary\n",
    "        y_train = y_train.values.ravel()\n",
    "        y_test = y_test.values.ravel()\n",
    "\n",
    "        # Standardize data\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "        return X_train_scaled,X_test_scaled,y_train,y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = model.elastic_net_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = preprocess_data(final_df, 'fantasy_points')\n",
    "\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict train and test\n",
    "y_pred_train = model.predict(x_train)\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "\n",
    "final_df['predictions'] = np.hstack([y_pred_train, y_pred_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    " final_df[['game_id',\n",
    " 'game_date',\n",
    " 'week',\n",
    " 'div_game',\n",
    " 'posteam',\n",
    " 'opponent_team',\n",
    " 'home_team',\n",
    " 'away_team',\n",
    " 'weather',\n",
    " 'stadium',\n",
    " 'spread_line',\n",
    " 'total_line',\n",
    " 'roof',\n",
    " 'surface',\n",
    " 'temp',\n",
    " 'wind',\n",
    " 'home_coach',\n",
    " 'away_coach',\n",
    " 'player_id',\n",
    " 'player_name',\n",
    " 'season']] = df_combined[['game_id',\n",
    " 'game_date',\n",
    " 'week',\n",
    " 'div_game',\n",
    " 'posteam',\n",
    " 'opponent_team',\n",
    " 'home_team',\n",
    " 'away_team',\n",
    " 'weather',\n",
    " 'stadium',\n",
    " 'spread_line',\n",
    " 'total_line',\n",
    " 'roof',\n",
    " 'surface',\n",
    " 'temp',\n",
    " 'wind',\n",
    " 'home_coach',\n",
    " 'away_coach',\n",
    " 'player_id',\n",
    " 'player_name',\n",
    " 'season']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('./rb_wr_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 5.321056013474444\n",
      "MSE: 55.95881634529496\n"
     ]
    }
   ],
   "source": [
    "# preds = ebm.predict(X_test_raw)\n",
    "\n",
    "# preds_df['actual'] = y_test['fantasy_points']\n",
    "\n",
    "\n",
    "\n",
    "print(\"MAE: \" + str(mean_absolute_error(y_pred_test, y_test)))\n",
    "\n",
    "print(\"MSE: \" + str(mean_squared_error(y_pred_test, y_test)))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
